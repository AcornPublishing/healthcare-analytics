{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter is intended for all audiences and is an integral part of the book.  We will demonstrate building predictive models for healthcare using example data and an example use case.  We will preprocess the data one feature at a time.  By the ed of the chapter, you will understand how to prepare a clinical dataset for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   width column_name  variable_type\n",
      "0      2      VMONTH    CATEGORICAL\n",
      "1      1       VDAYR    CATEGORICAL\n",
      "2      4     ARRTIME  NONPREDICTIVE\n",
      "3      4    WAITTIME     CONTINUOUS\n",
      "4      4         LOV  NONPREDICTIVE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "\n",
    "HOME_PATH = 'C:\\\\Users\\\\Vikas\\\\Desktop\\\\Bk\\\\health-it\\\\ed_predict\\\\data\\\\'\n",
    "\n",
    "df_helper = pd.read_csv(\n",
    "    HOME_PATH + 'ED_metadata.csv',\n",
    "    header=0, \n",
    "    dtype={'width': int, 'column_name': str, 'variable_type': str}\n",
    ")\n",
    "\n",
    "print(df_helper.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = df_helper['width'].tolist()\n",
    "col_names = df_helper['column_name'].tolist()\n",
    "var_types = df_helper['variable_type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ed = pd.read_fwf(\n",
    "    HOME_PATH + 'ED2013',\n",
    "    widths=width,\n",
    "    header=None,\n",
    "    dtype='str'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [TEMPF] is not in the [columns]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1433\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1434\u001b[1;33m                     \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1435\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1428\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[1;32m-> 1429\u001b[1;33m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [TEMPF] is not in the [columns]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1572bb70293d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_ed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TEMPF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TEMPF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TEMPF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1325\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    834\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 836\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    837\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1551\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1440\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vikas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1427\u001b[0m                                     \"key\")\n\u001b[0;32m   1428\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[1;32m-> 1429\u001b[1;33m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [TEMPF] is not in the [columns]'"
     ]
    }
   ],
   "source": [
    "df_ed.loc[:,'TEMPF'] = df_ed.loc[:,'TEMPF'].apply(pd.to_numeric)\n",
    "print(df_ed.groupby('TEMPF').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ed.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VMONTH VDAYR ARRTIME WAITTIME   LOV  AGE AGER AGEDAYS RESIDNCE SEX ...   \\\n",
      "0     01     3    0647     0033  0058  046    4     -07       01   2 ...    \n",
      "1     01     3    1841     0109  0150  056    4     -07       01   2 ...    \n",
      "2     01     3    1333     0084  0198  037    3     -07       01   2 ...    \n",
      "3     01     3    1401     0159  0276  007    1     -07       01   1 ...    \n",
      "4     01     4    1947     0114  0248  053    4     -07       01   1 ...    \n",
      "\n",
      "  RX12V3C1 RX12V3C2 RX12V3C3 RX12V3C4 SETTYPE  YEAR   CSTRATM   CPSUM   PATWT  \\\n",
      "0      nan      nan      nan      nan       3  2013  20113201  100020  002945   \n",
      "1      nan      nan      nan      nan       3  2013  20113201  100020  002945   \n",
      "2      nan      nan      nan      nan       3  2013  20113201  100020  002945   \n",
      "3      nan      nan      nan      nan       3  2013  20113201  100020  002945   \n",
      "4      nan      nan      nan      nan       3  2013  20113201  100020  002945   \n",
      "\n",
      "  EDWT  \n",
      "0  nan  \n",
      "1  nan  \n",
      "2  nan  \n",
      "3  nan  \n",
      "4  nan  \n",
      "\n",
      "[5 rows x 579 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_ed.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24777, 579)\n"
     ]
    }
   ],
   "source": [
    "print(df_ed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_cols = ['ADMITHOS','TRANOTH','TRANPSYC','OBSHOS','OBSDIS']\n",
    "\n",
    "df_ed.loc[:, response_cols] = df_ed.loc[:, response_cols].apply(pd.to_numeric)\n",
    "\n",
    "df_ed['ADMITTEMP'] = df_ed[response_cols].sum(axis=1)\n",
    "df_ed['ADMITFINAL'] = 0\n",
    "df_ed.loc[df_ed['ADMITTEMP'] >= 1, 'ADMITFINAL'] = 1\n",
    "\n",
    "df_ed.drop(response_cols, axis=1, inplace=True)\n",
    "df_ed.drop('ADMITTEMP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_target(data, target_name):\n",
    "    target = data[[target_name]]\n",
    "    data.drop(target_name, axis=1, inplace=True)\n",
    "    return (data, target)\n",
    "\n",
    "X, y = split_target(df_ed, 'ADMITFINAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADMITFINAL\n",
      "0    15996\n",
      "1     2586\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.groupby('ADMITFINAL').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMONTH\n",
      "01    1757\n",
      "02    1396\n",
      "03    1409\n",
      "04    1719\n",
      "05    2032\n",
      "06    1749\n",
      "07    1696\n",
      "08    1034\n",
      "09    1240\n",
      "10    1306\n",
      "11    1693\n",
      "12    1551\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.groupby('VMONTH').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_winter(vmonth):\n",
    "    if vmonth in ['12','01','02','03']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_train.loc[:,'WINTER'] = df_ed.loc[:,'VMONTH'].apply(is_winter)\n",
    "X_test.loc[:,'WINTER'] = df_ed.loc[:,'VMONTH'].apply(is_winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WINTER\n",
       "0    12469\n",
       "1     6113\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby('WINTER').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VDAYR\n",
       "1    2559\n",
       "2    2972\n",
       "3    2791\n",
       "4    2632\n",
       "5    2553\n",
       "6    2569\n",
       "7    2506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby('VDAYR').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_night(arrtime):\n",
    "    arrtime_int = int(arrtime)\n",
    "    if ((arrtime_int >= 0) & (arrtime_int < 800)):\n",
    "        return 1\n",
    "    elif ((arrtime_int >= 2000) & (arrtime_int < 2400)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_train.loc[:,'NIGHT'] = df_ed.loc[:,'ARRTIME'].apply(is_night)\n",
    "X_test.loc[:,'NIGHT'] = df_ed.loc[:,'ARRTIME'].apply(is_night)\n",
    "\n",
    "X_train.drop('ARRTIME', axis=1, inplace=True)\n",
    "X_test.drop('ARRTIME', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'WAITTIME'] = X_train.loc[:,'WAITTIME'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'WAITTIME'] = X_test.loc[:,'WAITTIME'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_impute_values(data,col):  \n",
    "    temp_mean = data.loc[(data[col] != -7) & (data[col] != -9), col].mean()\n",
    "    data.loc[(data[col] == -7) | (data[col] == -9), col] = temp_mean            \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_values(X_train,'WAITTIME')\n",
    "X_test = mean_impute_values(X_test,'WAITTIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.drop('LOV', axis=1, inplace=True)\n",
    "X_test.drop('LOV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'AGE'] = X_train.loc[:,'AGE'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'AGE'] = X_test.loc[:,'AGE'].apply(pd.to_numeric)\n",
    "\n",
    "X_train.drop('AGEDAYS', axis=1, inplace=True)\n",
    "X_test.drop('AGEDAYS', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)\n",
    "X_test.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VMONTH</th>\n",
       "      <th>VDAYR</th>\n",
       "      <th>WAITTIME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RESIDNCE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ETHUN</th>\n",
       "      <th>RACEUN</th>\n",
       "      <th>ARREMS</th>\n",
       "      <th>...</th>\n",
       "      <th>RX12V3C3</th>\n",
       "      <th>RX12V3C4</th>\n",
       "      <th>SETTYPE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>CSTRATM</th>\n",
       "      <th>CPSUM</th>\n",
       "      <th>PATWT</th>\n",
       "      <th>EDWT</th>\n",
       "      <th>WINTER</th>\n",
       "      <th>NIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>40300000</td>\n",
       "      <td>000024</td>\n",
       "      <td>003201</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>20213201</td>\n",
       "      <td>100091</td>\n",
       "      <td>003784</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>07</td>\n",
       "      <td>1</td>\n",
       "      <td>45.561676</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>20213201</td>\n",
       "      <td>100075</td>\n",
       "      <td>002214</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>-9</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>20413201</td>\n",
       "      <td>100227</td>\n",
       "      <td>002262</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>20413201</td>\n",
       "      <td>100242</td>\n",
       "      <td>002108</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VMONTH VDAYR   WAITTIME  AGE AGER RESIDNCE SEX ETHUN RACEUN ARREMS  \\\n",
       "15938     11     3  27.000000   58    4       01   1    02     01     01   \n",
       "5905      10     3   5.000000   91    6       02   1    02     02     01   \n",
       "4636      07     1  45.561676   29    3       01   1    02     02     02   \n",
       "9452      08     1  23.000000   20    2       01   2    02     -9     02   \n",
       "7558      02     4  32.000000   51    4       03   1    02     01     01   \n",
       "\n",
       "       ...  RX12V3C3 RX12V3C4 SETTYPE  YEAR   CSTRATM   CPSUM   PATWT EDWT  \\\n",
       "15938  ...       nan      nan       3  2013  40300000  000024  003201  nan   \n",
       "5905   ...       nan      nan       3  2013  20213201  100091  003784  nan   \n",
       "4636   ...       nan      nan       3  2013  20213201  100075  002214  nan   \n",
       "9452   ...       nan      nan       3  2013  20413201  100227  002262  nan   \n",
       "7558   ...       nan      nan       3  2013  20413201  100242  002108  nan   \n",
       "\n",
       "      WINTER NIGHT  \n",
       "15938      0     0  \n",
       "5905       0     1  \n",
       "4636       0     0  \n",
       "9452       0     0  \n",
       "7558       1     0  \n",
       "\n",
       "[5 rows x 570 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.drop('PAYTYPER', axis=1, inplace=True)\n",
    "X_test.drop('PAYTYPER', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'TEMPF')\n",
    "X_test = mean_impute_values(X_test,'TEMPF')\n",
    "\n",
    "X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(lambda x: float(x)/10)\n",
    "X_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(lambda x: float(x)/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15938     98.200000\n",
       "5905      98.100000\n",
       "4636      98.200000\n",
       "9452      98.200000\n",
       "7558      99.300000\n",
       "17878     99.000000\n",
       "21071     97.800000\n",
       "20990     98.600000\n",
       "4537      98.200000\n",
       "7025      99.300000\n",
       "2134      97.500000\n",
       "5212      97.400000\n",
       "9213      97.900000\n",
       "2306      97.000000\n",
       "6106      98.600000\n",
       "2727      98.282103\n",
       "4098      99.100000\n",
       "5233      98.800000\n",
       "5107     100.000000\n",
       "18327     98.900000\n",
       "19242     98.282103\n",
       "3868      97.900000\n",
       "12903     98.600000\n",
       "12763     98.700000\n",
       "8858      99.400000\n",
       "8955      97.900000\n",
       "16360     98.282103\n",
       "6857      97.100000\n",
       "6842      97.700000\n",
       "22073     97.900000\n",
       "Name: TEMPF, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['TEMPF'].head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'PULSE'] = X_train.loc[:,'PULSE'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'PULSE'] = X_test.loc[:,'PULSE'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_impute_vitals(data,col):  \n",
    "    temp_mean = data.loc[(data[col] != 998) & (data[col] != -9), col].mean()\n",
    "    data.loc[(data[col] == 998) | (data[col] == -9), col] = temp_mean            \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_vitals(X_train,'PULSE')\n",
    "X_test = mean_impute_vitals(X_test,'PULSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'RESPR'] = X_train.loc[:,'RESPR'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'RESPR'] = X_test.loc[:,'RESPR'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'RESPR')\n",
    "X_test = mean_impute_values(X_test,'RESPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'BPSYS'] = X_train.loc[:,'BPSYS'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'BPSYS'] = X_test.loc[:,'BPSYS'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'BPSYS')\n",
    "X_test = mean_impute_values(X_test,'BPSYS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'BPDIAS'] = X_train.loc[:,'BPDIAS'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'BPDIAS'] = X_test.loc[:,'BPDIAS'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_impute_bp_diast(data,col):  \n",
    "    temp_mean = data.loc[(data[col] != 998) & (data[col] != -9), col].mean()\n",
    "    data.loc[data[col] == 998, col] = 40\n",
    "    data.loc[data[col] == -9, col] = temp_mean            \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_values(X_train,'BPDIAS')\n",
    "X_test = mean_impute_values(X_test,'BPDIAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'POPCT'] = X_train.loc[:,'POPCT'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'POPCT'] = X_test.loc[:,'POPCT'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'POPCT')\n",
    "X_test = mean_impute_values(X_test,'POPCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMPF</th>\n",
       "      <th>PULSE</th>\n",
       "      <th>RESPR</th>\n",
       "      <th>BPSYS</th>\n",
       "      <th>BPDIAS</th>\n",
       "      <th>POPCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>98.200000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>98.100000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>98.200000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>98.200000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>99.300000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21071</th>\n",
       "      <td>97.800000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20990</th>\n",
       "      <td>98.600000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>98.200000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>99.300000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>97.500000</td>\n",
       "      <td>91.056517</td>\n",
       "      <td>18.0</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>97.400000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9213</th>\n",
       "      <td>97.900000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>98.600000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>98.282103</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>99.100000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>133.483987</td>\n",
       "      <td>78.127013</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5233</th>\n",
       "      <td>98.800000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>97.311242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18327</th>\n",
       "      <td>98.900000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TEMPF       PULSE  RESPR       BPSYS     BPDIAS       POPCT\n",
       "15938   98.200000  101.000000   22.0  159.000000  72.000000   98.000000\n",
       "5905    98.100000   70.000000   18.0  167.000000  79.000000   96.000000\n",
       "4636    98.200000   85.000000   20.0  113.000000  70.000000   98.000000\n",
       "9452    98.200000   84.000000   20.0  146.000000  72.000000   98.000000\n",
       "7558    99.300000  116.000000   18.0  131.000000  82.000000   96.000000\n",
       "17878   99.000000   73.000000   16.0  144.000000  91.000000   99.000000\n",
       "21071   97.800000   88.000000   18.0  121.000000  61.000000   98.000000\n",
       "20990   98.600000   67.000000   16.0  112.000000  65.000000   95.000000\n",
       "4537    98.200000   85.000000   20.0  113.000000  72.000000   99.000000\n",
       "7025    99.300000  172.000000   40.0  124.000000  80.000000  100.000000\n",
       "2134    97.500000   91.056517   18.0  146.000000  75.000000   94.000000\n",
       "5212    97.400000  135.000000   18.0  125.000000  71.000000   99.000000\n",
       "9213    97.900000   85.000000   18.0  153.000000  96.000000   99.000000\n",
       "2306    97.000000   67.000000   20.0  136.000000  75.000000   99.000000\n",
       "6106    98.600000   90.000000   18.0  109.000000  70.000000   98.000000\n",
       "2727    98.282103   83.000000   17.0  123.000000  48.000000   92.000000\n",
       "4098    99.100000  147.000000   20.0  133.483987  78.127013  100.000000\n",
       "5233    98.800000   81.000000   16.0  114.000000  78.000000   97.311242\n",
       "5107   100.000000   95.000000   24.0  133.000000  75.000000   94.000000\n",
       "18327   98.900000   84.000000   16.0  130.000000  85.000000   98.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['TEMPF','PULSE','RESPR','BPSYS','BPDIAS','POPCT']].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'PAINSCALE'] = X_train.loc[:,'PAINSCALE'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'PAINSCALE'] = X_test.loc[:,'PAINSCALE'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_impute_pain(data,col):  \n",
    "    temp_mean = data.loc[(data[col] != -8) & (data[col] != -9), col].mean()\n",
    "    data.loc[(data[col] == -8) | (data[col] == -9), col] = temp_mean            \n",
    "    return data\n",
    "\n",
    "X_train = mean_impute_pain(X_train,'PAINSCALE')\n",
    "X_test = mean_impute_pain(X_test,'PAINSCALE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfv_codes_path = HOME_PATH + 'RFV_CODES.csv'\n",
    "\n",
    "rfv_codes = pd.read_csv(rfv_codes_path,header=0,dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "\n",
    "def add_rfv_column(data,code,desc,rfv_columns):\n",
    "    column_name = 'rfv_' + sub(\" \", \"_\", desc)\n",
    "    data[column_name] = (data[rfv_columns] == rfv_code).any(axis=1).astype('int')\n",
    "    return data\n",
    "\n",
    "rfv_columns = ['RFV1','RFV2','RFV3']\n",
    "for (rfv_code,rfv_desc) in zip(\n",
    "    rfv_codes['Code'].tolist(),rfv_codes['Description'].tolist()\n",
    "):\n",
    "    X_train = add_rfv_column(\n",
    "        X_train,\n",
    "        rfv_code,\n",
    "        rfv_desc,\n",
    "        rfv_columns\n",
    "    )\n",
    "    X_test = add_rfv_column(\n",
    "        X_test,\n",
    "        rfv_code,\n",
    "        rfv_desc,\n",
    "        rfv_columns      \n",
    "    )\n",
    "    \n",
    "# Remove original RFV columns\n",
    "X_train.drop(rfv_columns, axis=1, inplace=True)\n",
    "X_test.drop(rfv_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VMONTH</th>\n",
       "      <th>VDAYR</th>\n",
       "      <th>WAITTIME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGER</th>\n",
       "      <th>RESIDNCE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>ETHUN</th>\n",
       "      <th>RACEUN</th>\n",
       "      <th>ARREMS</th>\n",
       "      <th>...</th>\n",
       "      <th>rfv_Entry_of_none_or_no_complaint</th>\n",
       "      <th>rfv_Insufficient_information</th>\n",
       "      <th>rfv_Driver's_license_examination_DOT_</th>\n",
       "      <th>rfv_Illegible_entry</th>\n",
       "      <th>rfv_Insurance_examination_</th>\n",
       "      <th>rfv_Disability_examination_</th>\n",
       "      <th>rfv_Worker’s_comp_exam</th>\n",
       "      <th>rfv_Premarital_examination</th>\n",
       "      <th>rfv_Premarital_blood_test</th>\n",
       "      <th>rfv_Direct_admission_to_hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>07</td>\n",
       "      <td>1</td>\n",
       "      <td>45.561676</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>-9</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VMONTH VDAYR   WAITTIME  AGE AGER RESIDNCE SEX ETHUN RACEUN ARREMS  \\\n",
       "15938     11     3  27.000000   58    4       01   1    02     01     01   \n",
       "5905      10     3   5.000000   91    6       02   1    02     02     01   \n",
       "4636      07     1  45.561676   29    3       01   1    02     02     02   \n",
       "9452      08     1  23.000000   20    2       01   2    02     -9     02   \n",
       "7558      02     4  32.000000   51    4       03   1    02     01     01   \n",
       "\n",
       "                     ...                rfv_Entry_of_none_or_no_complaint  \\\n",
       "15938                ...                                                0   \n",
       "5905                 ...                                                0   \n",
       "4636                 ...                                                0   \n",
       "9452                 ...                                                0   \n",
       "7558                 ...                                                0   \n",
       "\n",
       "      rfv_Insufficient_information rfv_Driver's_license_examination_DOT_  \\\n",
       "15938                            0                                     0   \n",
       "5905                             0                                     0   \n",
       "4636                             0                                     0   \n",
       "9452                             0                                     0   \n",
       "7558                             0                                     0   \n",
       "\n",
       "      rfv_Illegible_entry rfv_Insurance_examination_  \\\n",
       "15938                   0                          0   \n",
       "5905                    0                          0   \n",
       "4636                    0                          0   \n",
       "9452                    0                          0   \n",
       "7558                    0                          0   \n",
       "\n",
       "      rfv_Disability_examination_ rfv_Worker’s_comp_exam  \\\n",
       "15938                           0                      0   \n",
       "5905                            0                      0   \n",
       "4636                            0                      0   \n",
       "9452                            0                      0   \n",
       "7558                            0                      0   \n",
       "\n",
       "      rfv_Premarital_examination rfv_Premarital_blood_test  \\\n",
       "15938                          0                         0   \n",
       "5905                           0                         0   \n",
       "4636                           0                         0   \n",
       "9452                           0                         0   \n",
       "7558                           0                         0   \n",
       "\n",
       "       rfv_Direct_admission_to_hospital  \n",
       "15938                                 0  \n",
       "5905                                  0  \n",
       "4636                                  0  \n",
       "9452                                  0  \n",
       "7558                                  0  \n",
       "\n",
       "[5 rows x 1264 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inj_cols = [\n",
    "    'INJURY','INJR1','INJR2','INJPOISAD','INJPOISADR1',\n",
    "    'INJPOISADR2','INTENT','INJDETR','INJDETR1','INJDETR2',\n",
    "    'CAUSE1','CAUSE2','CAUSE3','CAUSE1R','CAUSE2R','CAUSE3R'\n",
    "]\n",
    "\n",
    "X_train.drop(inj_cols, axis=1, inplace=True)\n",
    "X_test.drop(inj_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diag_cols= [\n",
    "    'DIAG1','DIAG2','DIAG3',\n",
    "    'PRDIAG1','PRDIAG2','PRDIAG3',\n",
    "    'DIAG1R','DIAG2R','DIAG3R'\n",
    "]\n",
    "\n",
    "X_train.drop(diag_cols, axis=1, inplace=True)\n",
    "X_test.drop(diag_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,'TOTCHRON'] = X_train.loc[:,'TOTCHRON'].apply(pd.to_numeric)\n",
    "X_test.loc[:,'TOTCHRON'] = X_test.loc[:,'TOTCHRON'].apply(pd.to_numeric)\n",
    "\n",
    "X_train = mean_impute_values(X_train,'TOTCHRON')\n",
    "X_test = mean_impute_values(X_test,'TOTCHRON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_cols = [\n",
    "    'ABG','BAC','BLOODCX','BNP','BUNCREAT',\n",
    "    'CARDENZ','CBC','DDIMER','ELECTROL','GLUCOSE',\n",
    "    'LACTATE','LFT','PTTINR','OTHERBLD','CARDMON',\n",
    "    'EKG','HIVTEST','FLUTEST','PREGTEST','TOXSCREN',\n",
    "    'URINE','WOUNDCX','URINECX','OTHRTEST','ANYIMAGE',\n",
    "    'XRAY','IVCONTRAST','CATSCAN','CTAB','CTCHEST',\n",
    "    'CTHEAD','CTOTHER','CTUNK','MRI','ULTRASND',\n",
    "    'OTHIMAGE','TOTDIAG','DIAGSCRN'\n",
    "]\n",
    "\n",
    "X_train.drop(testing_cols, axis=1, inplace=True)\n",
    "X_test.drop(testing_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc_cols = [\n",
    "    'PROC','BPAP','BLADCATH','CASTSPLINT','CENTLINE',\n",
    "    'CPR','ENDOINT','INCDRAIN','IVFLUIDS','LUMBAR',\n",
    "    'NEBUTHER','PELVIC','SKINADH','SUTURE','OTHPROC',\n",
    "    'TOTPROC'\n",
    "]\n",
    "\n",
    "X_train.drop(proc_cols, axis=1, inplace=True)\n",
    "X_test.drop(proc_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "med_cols = [\n",
    "    'MED1','MED2','MED3','MED4','MED5',\n",
    "    'MED6','MED7','MED8','MED9','MED10',\n",
    "    'MED11','MED12','GPMED1','GPMED2','GPMED3',\n",
    "    'GPMED4','GPMED5','GPMED6','GPMED7','GPMED8',\n",
    "    'GPMED9','GPMED10','GPMED11','GPMED12','NUMGIV',\n",
    "    'NUMDIS','NUMMED',\n",
    "]\n",
    "\n",
    "X_train.drop(med_cols, axis=1, inplace=True)\n",
    "X_test.drop(med_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prov_cols = [\n",
    "    'NOPROVID','ATTPHYS','RESINT','CONSULT','RNLPN',\n",
    "    'NURSEPR','PHYSASST','EMT','MHPROV','OTHPROV'\n",
    "]\n",
    "\n",
    "X_train.drop(prov_cols, axis=1, inplace=True)\n",
    "X_test.drop(prov_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disp_cols = [\n",
    "    'NODISP','NOFU','RETRNED','RETREFFU','LEFTBTRI',\n",
    "    'LEFTAMA','DOA','DIEDED','TRANNH','OTHDISP',\n",
    "    'ADMIT','ADMTPHYS','BOARDED','LOS','HDDIAG1',\n",
    "    'HDDIAG2','HDDIAG3','HDDIAG1R','HDDIAG2R','HDDIAG3R',\n",
    "    'HDSTAT','ADISP','OBSSTAY','STAY24'\n",
    "]\n",
    "\n",
    "X_train.drop(disp_cols, axis=1, inplace=True)\n",
    "X_test.drop(disp_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_cols = [\n",
    "    'AGEFL','BDATEFL','SEXFL','ETHNICFL','RACERFL'\n",
    "]\n",
    "\n",
    "X_train.drop(imp_cols, axis=1, inplace=True)\n",
    "X_test.drop(imp_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    'HOSPCODE','PATCODE'\n",
    "]\n",
    "\n",
    "X_train.drop(id_cols, axis=1, inplace=True)\n",
    "X_test.drop(id_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emr_cols = [\n",
    "    'EBILLANYE','EMRED','HHSMUE','EHRINSE','EDEMOGE',\n",
    "    'EDEMOGER','EPROLSTE','EPROLSTER','EVITALE','EVITALER',\n",
    "    'ESMOKEE','ESMOKEER','EPNOTESE','EPNOTESER','EMEDALGE',\n",
    "    'EMEDALGER','ECPOEE','ECPOEER','ESCRIPE','ESCRIPER',\n",
    "    'EWARNE','EWARNER','EREMINDE','EREMINDER','ECTOEE',\n",
    "    'ECTOEER','EORDERE','EORDERER','ERESULTE','ERESULTER',\n",
    "    'EGRAPHE','EGRAPHER','EIMGRESE','EIMGRESER','EPTEDUE',\n",
    "    'EPTEDUER','ECQME','ECQMER','EGENLISTE','EGENLISTER',\n",
    "    'EIMMREGE','EIMMREGER','ESUME','ESUMER','EMSGE',\n",
    "    'EMSGER','EHLTHINFOE','EHLTHINFOER','EPTRECE','EPTRECER',\n",
    "    'EMEDIDE','EMEDIDER','ESHAREE','ESHAREEHRE','ESHAREWEBE',\n",
    "    'ESHAREOTHE','ESHAREUNKE','ESHAREREFE','LABRESE1','LABRESE2',\n",
    "    'LABRESE3','LABRESE4','LABRESUNKE','LABRESREFE','IMAGREPE1',\n",
    "    'IMAGREPE2','IMAGREPE3','IMAGREPE4','IMAGREPUNKE','IMAGREPREFE',\n",
    "    'PTPROBE1','PTPROBE2','PTPROBE3','PTPROBE4','PTPROBUNKE',\n",
    "    'PTPROBREFE','MEDLISTE1','MEDLISTE2','MEDLISTE3','MEDLISTE4',\n",
    "    'MEDLISTUNKE','MEDLISTREFE','ALGLISTE1','ALGLISTE2','ALGLISTE3',\n",
    "    'ALGLISTE4','ALGLISTUNKE','ALGLISTREFE','EDPRIM','EDINFO',\n",
    "    'MUINC','MUYEAR'\n",
    "]\n",
    "\n",
    "X_train.drop(emr_cols, axis=1, inplace=True)\n",
    "X_test.drop(emr_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drug_id_cols = [\n",
    "    'DRUGID1','DRUGID2','DRUGID3','DRUGID4','DRUGID5',\n",
    "    'DRUGID6','DRUGID7','DRUGID8','DRUGID9','DRUGID10',\n",
    "    'DRUGID11','DRUGID12'\n",
    "]\n",
    "\n",
    "drug_lev1_cols = [\n",
    "    'RX1V1C1','RX1V1C2','RX1V1C3','RX1V1C4',\n",
    "    'RX2V1C1','RX2V1C2','RX2V1C3','RX2V1C4',\n",
    "    'RX3V1C1','RX3V1C2','RX3V1C3','RX3V1C4',\n",
    "    'RX4V1C1','RX4V1C2','RX4V1C3','RX4V1C4',\n",
    "    'RX5V1C1','RX5V1C2','RX5V1C3','RX5V1C4',\n",
    "    'RX6V1C1','RX6V1C2','RX6V1C3','RX6V1C4',\n",
    "    'RX7V1C1','RX7V1C2','RX7V1C3','RX7V1C4',\n",
    "    'RX8V1C1','RX8V1C2','RX8V1C3','RX8V1C4',\n",
    "    'RX9V1C1','RX9V1C2','RX9V1C3','RX9V1C4',\n",
    "    'RX10V1C1','RX10V1C2','RX10V1C3','RX10V1C4',\n",
    "    'RX11V1C1','RX11V1C2','RX11V1C3','RX11V1C4',\n",
    "    'RX12V1C1','RX12V1C2','RX12V1C3','RX12V1C4'\n",
    "]\n",
    "\n",
    "drug_lev2_cols = [\n",
    "    'RX1V2C1','RX1V2C2','RX1V2C3','RX1V2C4',\n",
    "    'RX2V2C1','RX2V2C2','RX2V2C3','RX2V2C4',\n",
    "    'RX3V2C1','RX3V2C2','RX3V2C3','RX3V2C4',\n",
    "    'RX4V2C1','RX4V2C2','RX4V2C3','RX4V2C4',\n",
    "    'RX5V2C1','RX5V2C2','RX5V2C3','RX5V2C4',\n",
    "    'RX6V2C1','RX6V2C2','RX6V2C3','RX6V2C4',\n",
    "    'RX7V2C1','RX7V2C2','RX7V2C3','RX7V2C4',\n",
    "    'RX8V2C1','RX8V2C2','RX8V2C3','RX8V2C4',\n",
    "    'RX9V2C1','RX9V2C2','RX9V2C3','RX9V2C4',\n",
    "    'RX10V2C1','RX10V2C2','RX10V2C3','RX10V2C4',\n",
    "    'RX11V2C1','RX11V2C2','RX11V2C3','RX11V2C4',\n",
    "    'RX12V2C1','RX12V2C2','RX12V2C3','RX12V2C4'\n",
    "]\n",
    "\n",
    "drug_lev3_cols = [\n",
    "    'RX1V3C1','RX1V3C2','RX1V3C3','RX1V3C4',\n",
    "    'RX2V3C1','RX2V3C2','RX2V3C3','RX2V3C4',\n",
    "    'RX3V3C1','RX3V3C2','RX3V3C3','RX3V3C4',\n",
    "    'RX4V3C1','RX4V3C2','RX4V3C3','RX4V3C4',\n",
    "    'RX5V3C1','RX5V3C2','RX5V3C3','RX5V3C4',\n",
    "    'RX6V3C1','RX6V3C2','RX6V3C3','RX6V3C4',\n",
    "    'RX7V3C1','RX7V3C2','RX7V3C3','RX7V3C4',\n",
    "    'RX8V3C1','RX8V3C2','RX8V3C3','RX8V3C4',\n",
    "    'RX9V3C1','RX9V3C2','RX9V3C3','RX9V3C4',\n",
    "    'RX10V3C1','RX10V3C2','RX10V3C3','RX10V3C4',\n",
    "    'RX11V3C1','RX11V3C2','RX11V3C3','RX11V3C4',\n",
    "    'RX12V3C1','RX12V3C2','RX12V3C3','RX12V3C4'\n",
    "]\n",
    "\n",
    "addl_drug_cols = [\n",
    "    'PRESCR1','CONTSUB1','COMSTAT1','RX1CAT1','RX1CAT2',\n",
    "    'RX1CAT3','RX1CAT4','PRESCR2','CONTSUB2','COMSTAT2',\n",
    "    'RX2CAT1','RX2CAT2','RX2CAT3','RX2CAT4','PRESCR3','CONTSUB3',\n",
    "    'COMSTAT3','RX3CAT1','RX3CAT2','RX3CAT3','RX3CAT4','PRESCR4',\n",
    "    'CONTSUB4','COMSTAT4','RX4CAT1','RX4CAT2','RX4CAT3',\n",
    "    'RX4CAT4','PRESCR5','CONTSUB5','COMSTAT5','RX5CAT1',\n",
    "    'RX5CAT2','RX5CAT3','RX5CAT4','PRESCR6','CONTSUB6',\n",
    "    'COMSTAT6','RX6CAT1','RX6CAT2','RX6CAT3','RX6CAT4','PRESCR7',\n",
    "    'CONTSUB7','COMSTAT7','RX7CAT1','RX7CAT2','RX7CAT3',\n",
    "    'RX7CAT4','PRESCR8','CONTSUB8','COMSTAT8','RX8CAT1',\n",
    "    'RX8CAT2','RX8CAT3','RX8CAT4','PRESCR9','CONTSUB9',\n",
    "    'COMSTAT9','RX9CAT1','RX9CAT2','RX9CAT3','RX9CAT4',\n",
    "    'PRESCR10','CONTSUB10','COMSTAT10','RX10CAT1','RX10CAT2',\n",
    "    'RX10CAT3','RX10CAT4','PRESCR11','CONTSUB11','COMSTAT11',\n",
    "    'RX11CAT1','RX11CAT2','RX11CAT3','RX11CAT4','PRESCR12',\n",
    "    'CONTSUB12','COMSTAT12','RX12CAT1','RX12CAT2','RX12CAT3',\n",
    "    'RX12CAT4'\n",
    "]\n",
    "\n",
    "X_train.drop(drug_id_cols, axis=1, inplace=True)\n",
    "X_train.drop(drug_lev1_cols, axis=1, inplace=True)\n",
    "X_train.drop(drug_lev2_cols, axis=1, inplace=True)\n",
    "X_train.drop(drug_lev3_cols, axis=1, inplace=True)\n",
    "X_train.drop(addl_drug_cols, axis=1, inplace=True)\n",
    "\n",
    "X_test.drop(drug_id_cols, axis=1, inplace=True)\n",
    "X_test.drop(drug_lev1_cols, axis=1, inplace=True)\n",
    "X_test.drop(drug_lev2_cols, axis=1, inplace=True)\n",
    "X_test.drop(drug_lev3_cols, axis=1, inplace=True)\n",
    "X_test.drop(addl_drug_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "design_cols = ['CSTRATM','CPSUM','PATWT','EDWT']\n",
    "\n",
    "X_train.drop(design_cols, axis=1, inplace=True)\n",
    "X_test.drop(design_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categ_cols = df_helper.loc[\n",
    "    df_helper['variable_type'] == 'CATEGORICAL', 'column_name'\n",
    "]\n",
    "\n",
    "one_hot_cols = list(set(categ_cols) & set(X_train.columns))\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns=one_hot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[:,X_train.columns] = X_train.loc[:,X_train.columns].apply(pd.to_numeric)\n",
    "X_test.loc[:,X_test.columns] = X_test.loc[:,X_test.columns].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_cols = X_train.columns\n",
    "X_test_cols = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "Training accuracy: 0.888978581423\n",
      "Validation accuracy: 0.884261501211\n",
      "         coef                                             column\n",
      "346  2.825056                     rfv_Symptoms_of_onset_of_labor\n",
      "696  1.618454                   rfv_Adverse_effect_of_drug_abuse\n",
      "95   1.467790                    rfv_Delusions_or_hallucinations\n",
      "108  1.435026  rfv_Other_symptoms_or_problems_relating_to_psy...\n",
      "688  1.287535                                rfv_Suicide_attempt\n",
      "895  1.265043                                          IMMEDR_01\n",
      "520  1.264023  rfv_General_psychiatric_or_psychological_exami...\n",
      "278  1.213235                                       rfv_Jaundice\n",
      "712  1.139245         rfv_For_other_and_unspecified_test_results\n",
      "469  1.084806                            rfv_Other_heart_disease\n",
      "42   1.059201                               rfv_General_weakness\n",
      "88   1.054595                                    rfv_Depression_\n",
      "500  1.050758  rfv_Diagnosed_complications_of_pregnancy_and_p...\n",
      "470  0.988462                        rfv_Cerebrovascular_disease\n",
      "201  0.971254         rfv_Labored_or_difficult_breathing_dyspnea\n",
      "442  0.956917                                         rfv_Anemia\n",
      "607  0.937208                         rfv_Medical_Counseling_NOS\n",
      "89   0.916790                               rfv_Hostile_behavior\n",
      "55   0.911398                            rfv_Chest_pain_soreness\n",
      "130  0.909472  rfv_Other_symptoms_referable_to_the_nervous_sy...\n",
      "80   0.883354                  rfv_Disorders_of_motor_functions_\n",
      "578  0.838795                                        rfv_Alcohol\n",
      "640  0.836005                                            rfv_Leg\n",
      "757  0.832182                                          INCSHX_-8\n",
      "896  0.803593                                          IMMEDR_02\n",
      "129  0.797434                                       rfv_Slurring\n",
      "445  0.767028                           rfv_Functional_psychoses\n",
      "85   0.750699                        rfv_Behavioral_disturbances\n",
      "126  0.747121                            rfv_Weakness_neurologic\n",
      "197  0.741385                            rfv_Shortness_of_breath\n",
      "..        ...                                                ...\n",
      "745 -0.427793                                        ADVTRIAG_-8\n",
      "280 -0.429202                                  rfv_Constipation_\n",
      "669 -0.445590                                       rfv_Shoulder\n",
      "344 -0.491872                  rfv_Uterine_and_vaginal_bleeding_\n",
      "765 -0.493756                                          EDPTOR_-8\n",
      "178 -0.499313                                 rfv_Abnormal_color\n",
      "758 -0.508392                                          INCSHX_-9\n",
      "571 -0.558602                            rfv_Postoperative_visit\n",
      "668 -0.582376                             rfv_Animal_snake_human\n",
      "876 -0.583871                                       TOTHRDIVR_-9\n",
      "643 -0.586005                                  rfv_Foot_and_toes\n",
      "737 -0.591627                                         HLISTED_-8\n",
      "826 -0.614043                                         BEDDATA_06\n",
      "207 -0.618600                        rfv_Nosebleed_epistaxis_NEC\n",
      "285 -0.633296                       rfv_Blood_in_urine_hematuria\n",
      "849 -0.680649                                          OBSSEP_02\n",
      "665 -0.695856                                         rfv_Insect\n",
      "649 -0.732346                            rfv_Head_neck_and_face_\n",
      "679 -0.748975                                 rfv_Cardiac_arrest\n",
      "467 -0.790908                      rfv_Hypertension_hypertensive\n",
      "898 -0.839861                                          IMMEDR_04\n",
      "823 -0.848631                                         BEDDATA_03\n",
      "625 -0.873828                               rfv_Hand_and_fingers\n",
      "371 -0.960739                                      rfv_Skin_rash\n",
      "188 -0.963524                                  rfv_Earache_pain_\n",
      "217 -0.968058                                       rfv_Soreness\n",
      "899 -1.019763                                          IMMEDR_05\n",
      "604 -1.075670                      rfv_Suture__insertion_removal\n",
      "235 -1.140021                                      rfv_Toothache\n",
      "30  -1.692650                                           LEFTATRI\n",
      "\n",
      "[941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [LogisticRegression()]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    \n",
    "    coefs = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'coef': [clf.coef_[0,i] for i in range(len(X_train_cols))]\n",
    "    }\n",
    "    df_coefs = pd.DataFrame(coefs)\n",
    "    print(df_coefs.sort_values('coef', axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "Training accuracy: 1.0\n",
      "Validation accuracy: 0.885391444713\n",
      "                                                column       imp\n",
      "1                                                  AGE  0.039517\n",
      "13                                               PULSE  0.028348\n",
      "15                                               BPSYS  0.026833\n",
      "12                                               TEMPF  0.025898\n",
      "16                                              BPDIAS  0.025844\n",
      "0                                             WAITTIME  0.025111\n",
      "14                                               RESPR  0.021329\n",
      "17                                               POPCT  0.020407\n",
      "29                                            TOTCHRON  0.018417\n",
      "896                                          IMMEDR_02  0.016714\n",
      "751                                          ARREMS_01  0.016159\n",
      "18                                           PAINSCALE  0.016102\n",
      "886                                          NOCHRON_1  0.011680\n",
      "885                                          NOCHRON_0  0.011608\n",
      "752                                          ARREMS_02  0.011370\n",
      "5                                             PAYMCARE  0.010624\n",
      "796                                             AGER_6  0.009955\n",
      "777                                            ONO2_01  0.009806\n",
      "108  rfv_Other_symptoms_or_problems_relating_to_psy...  0.008785\n",
      "898                                          IMMEDR_04  0.008081\n",
      "55                             rfv_Chest_pain_soreness  0.007799\n",
      "31                                             SURGDAY  0.007137\n",
      "2                                                  SEX  0.006725\n",
      "197                            rfv_Shortness_of_breath  0.006655\n",
      "34                                               NIGHT  0.006052\n",
      "778                                            ONO2_02  0.005998\n",
      "4                                              PAYPRIV  0.005854\n",
      "897                                          IMMEDR_03  0.005840\n",
      "23                                                 CHF  0.005690\n",
      "794                                             AGER_4  0.005235\n",
      "..                                                 ...       ...\n",
      "427           rfv_Cancer_skin_and_subcutaneous_tissues  0.000000\n",
      "701  rfv_Adverse_effects_of_terrorism_and_bioterrorism  0.000000\n",
      "700            rfv_Adverse_effects_of_secondhand_smoke  0.000000\n",
      "698                              rfv_Alcohol_poisoning  0.000000\n",
      "693                                 rfv_Food_poisoning  0.000000\n",
      "731                          rfv_Premarital_blood_test  0.000000\n",
      "692                        rfv_Unintentional_poisoning  0.000000\n",
      "447           rfv_Personality_and_character_disorders_  0.000000\n",
      "452                     rfv_Attention_deficit_disorder  0.000000\n",
      "454          rfv_Parkinson's_disease_paralysis_agitans  0.000000\n",
      "683                                       rfv_Drowning  0.000000\n",
      "682                                    rfv_Elder_abuse  0.000000\n",
      "418                 rfv_Intestinal_infectious_diseases  0.000000\n",
      "713  rfv_For_results_of_test_for_human_immunodefici...  0.000000\n",
      "714  rfv_Physical_examination_required_for_school_o...  0.000000\n",
      "417                             rfv_Hemorrhagic_fevers  0.000000\n",
      "717                 rfv_Executive_physical_examination  0.000000\n",
      "718       rfv_Physical_examination_required_for_school  0.000000\n",
      "415                        rfv_Pigeontoed_feet_turn_in  0.000000\n",
      "720                rfv_Patient_unable_to_speak_English  0.000000\n",
      "414                               rfv_Posture_problems  0.000000\n",
      "722  rfv_Physical_examination_for_extracurricular_a...  0.000000\n",
      "413                           rfv_Bowlegged_knockkneed  0.000000\n",
      "411             rfv_Musculoskeletal_deformities_Rabies  0.000000\n",
      "726                                rfv_Illegible_entry  0.000000\n",
      "727                         rfv_Insurance_examination_  0.000000\n",
      "409                 rfv_Symptoms_of_unspecified_joints  0.000000\n",
      "729                             rfv_Worker’s_comp_exam  0.000000\n",
      "730                         rfv_Premarital_examination  0.000000\n",
      "101                    rfv_Homosexuality_concerns_with  0.000000\n",
      "\n",
      "[941 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs_rf = [RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "for clf in clfs_rf:\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    \n",
    "    imps = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'imp': [clf.feature_importances_[i] for i in range(len(X_train_cols))]\n",
    "    }\n",
    "    df_imps = pd.DataFrame(imps)\n",
    "    print(df_imps.sort_values('imp', axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150-layer network:\n",
      "Iteration 1, loss = 0.46076467\n",
      "Iteration 2, loss = 0.26234740\n",
      "Iteration 3, loss = 0.22560798\n",
      "Iteration 4, loss = 0.20510042\n",
      "Iteration 5, loss = 0.18719500\n",
      "Iteration 6, loss = 0.17035915\n",
      "Iteration 7, loss = 0.15348667\n",
      "Iteration 8, loss = 0.13856548\n",
      "Iteration 9, loss = 0.12282734\n",
      "Iteration 10, loss = 0.11028724\n",
      "Iteration 11, loss = 0.09775385\n",
      "Iteration 12, loss = 0.08738506\n",
      "Iteration 13, loss = 0.07620047\n",
      "Iteration 14, loss = 0.06739526\n",
      "Iteration 15, loss = 0.05887055\n",
      "Iteration 16, loss = 0.05178343\n",
      "Iteration 17, loss = 0.04491800\n",
      "Iteration 18, loss = 0.03962271\n",
      "Iteration 19, loss = 0.03478394\n",
      "Iteration 20, loss = 0.03108104\n",
      "Iteration 21, loss = 0.02690175\n",
      "Iteration 22, loss = 0.02353544\n",
      "Iteration 23, loss = 0.02143845\n",
      "Iteration 24, loss = 0.01861292\n",
      "Iteration 25, loss = 0.01691052\n",
      "Iteration 26, loss = 0.01601220\n",
      "Iteration 27, loss = 0.01372547\n",
      "Iteration 28, loss = 0.01236152\n",
      "Iteration 29, loss = 0.01601453\n",
      "Iteration 30, loss = 0.01147601\n",
      "Iteration 31, loss = 0.00895784\n",
      "Iteration 32, loss = 0.00856147\n",
      "Iteration 33, loss = 0.00787746\n",
      "Iteration 34, loss = 0.00702450\n",
      "Iteration 35, loss = 0.00701210\n",
      "Iteration 36, loss = 0.00577559\n",
      "Iteration 37, loss = 0.00705518\n",
      "Iteration 38, loss = 0.00629064\n",
      "Iteration 39, loss = 0.00454743\n",
      "Iteration 40, loss = 0.00440559\n",
      "Iteration 41, loss = 0.00409148\n",
      "Iteration 42, loss = 0.00859124\n",
      "Iteration 43, loss = 0.00597604\n",
      "Iteration 44, loss = 0.00419269\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training accuracy: 0.999730922398\n",
      "Validation accuracy: 0.872800645682\n",
      "100-layer network:\n",
      "Iteration 1, loss = 0.36467144\n",
      "Iteration 2, loss = 0.25583546\n",
      "Iteration 3, loss = 0.22768336\n",
      "Iteration 4, loss = 0.20659452\n",
      "Iteration 5, loss = 0.18897644\n",
      "Iteration 6, loss = 0.17436433\n",
      "Iteration 7, loss = 0.15784650\n",
      "Iteration 8, loss = 0.14402271\n",
      "Iteration 9, loss = 0.12901401\n",
      "Iteration 10, loss = 0.11629953\n",
      "Iteration 11, loss = 0.10364751\n",
      "Iteration 12, loss = 0.09281835\n",
      "Iteration 13, loss = 0.08292143\n",
      "Iteration 14, loss = 0.07190723\n",
      "Iteration 15, loss = 0.06361049\n",
      "Iteration 16, loss = 0.05723655\n",
      "Iteration 17, loss = 0.05153336\n",
      "Iteration 18, loss = 0.04535898\n",
      "Iteration 19, loss = 0.03997295\n",
      "Iteration 20, loss = 0.03603982\n",
      "Iteration 21, loss = 0.03205142\n",
      "Iteration 22, loss = 0.02931471\n",
      "Iteration 23, loss = 0.02677675\n",
      "Iteration 24, loss = 0.02349716\n",
      "Iteration 25, loss = 0.02064724\n",
      "Iteration 26, loss = 0.01857347\n",
      "Iteration 27, loss = 0.01667893\n",
      "Iteration 28, loss = 0.01449690\n",
      "Iteration 29, loss = 0.01338780\n",
      "Iteration 30, loss = 0.01198282\n",
      "Iteration 31, loss = 0.01287982\n",
      "Iteration 32, loss = 0.01094508\n",
      "Iteration 33, loss = 0.00913338\n",
      "Iteration 34, loss = 0.00888694\n",
      "Iteration 35, loss = 0.00794759\n",
      "Iteration 36, loss = 0.00771177\n",
      "Iteration 37, loss = 0.00725242\n",
      "Iteration 38, loss = 0.00675520\n",
      "Iteration 39, loss = 0.00695894\n",
      "Iteration 40, loss = 0.00568068\n",
      "Iteration 41, loss = 0.00553163\n",
      "Iteration 42, loss = 0.00494839\n",
      "Iteration 43, loss = 0.00662863\n",
      "Iteration 44, loss = 0.00402249\n",
      "Iteration 45, loss = 0.00444601\n",
      "Iteration 46, loss = 0.00351715\n",
      "Iteration 47, loss = 0.00302289\n",
      "Iteration 48, loss = 0.00303747\n",
      "Iteration 49, loss = 0.00310383\n",
      "Iteration 50, loss = 0.00243504\n",
      "Iteration 51, loss = 0.00224850\n",
      "Iteration 52, loss = 0.00432079\n",
      "Iteration 53, loss = 0.00701795\n",
      "Iteration 54, loss = 0.01373316\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training accuracy: 0.996448175654\n",
      "Validation accuracy: 0.871025020178\n",
      "80-layer network:\n",
      "Iteration 1, loss = 0.35424607\n",
      "Iteration 2, loss = 0.25931610\n",
      "Iteration 3, loss = 0.23398837\n",
      "Iteration 4, loss = 0.21643147\n",
      "Iteration 5, loss = 0.20053383\n",
      "Iteration 6, loss = 0.18453794\n",
      "Iteration 7, loss = 0.16956016\n",
      "Iteration 8, loss = 0.15512725\n",
      "Iteration 9, loss = 0.13974845\n",
      "Iteration 10, loss = 0.12618417\n",
      "Iteration 11, loss = 0.11374148\n",
      "Iteration 12, loss = 0.10286205\n",
      "Iteration 13, loss = 0.09374080\n",
      "Iteration 14, loss = 0.08299831\n",
      "Iteration 15, loss = 0.07458615\n",
      "Iteration 16, loss = 0.06720982\n",
      "Iteration 17, loss = 0.06065301\n",
      "Iteration 18, loss = 0.05578838\n",
      "Iteration 19, loss = 0.04908027\n",
      "Iteration 20, loss = 0.04437348\n",
      "Iteration 21, loss = 0.04027353\n",
      "Iteration 22, loss = 0.03716132\n",
      "Iteration 23, loss = 0.03311529\n",
      "Iteration 24, loss = 0.02970335\n",
      "Iteration 25, loss = 0.02733351\n",
      "Iteration 26, loss = 0.02477993\n",
      "Iteration 27, loss = 0.02212176\n",
      "Iteration 28, loss = 0.02099495\n",
      "Iteration 29, loss = 0.01922345\n",
      "Iteration 30, loss = 0.01739549\n",
      "Iteration 31, loss = 0.01535135\n",
      "Iteration 32, loss = 0.01374606\n",
      "Iteration 33, loss = 0.01252576\n",
      "Iteration 34, loss = 0.01129300\n",
      "Iteration 35, loss = 0.01066647\n",
      "Iteration 36, loss = 0.00983580\n",
      "Iteration 37, loss = 0.00888950\n",
      "Iteration 38, loss = 0.00823613\n",
      "Iteration 39, loss = 0.00779760\n",
      "Iteration 40, loss = 0.00672308\n",
      "Iteration 41, loss = 0.00623289\n",
      "Iteration 42, loss = 0.01069552\n",
      "Iteration 43, loss = 0.00957822\n",
      "Iteration 44, loss = 0.00650871\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training accuracy: 0.999623291357\n",
      "Validation accuracy: 0.873930589185\n",
      "60-layer network:\n",
      "Iteration 1, loss = 0.43226679\n",
      "Iteration 2, loss = 0.27582112\n",
      "Iteration 3, loss = 0.24175419\n",
      "Iteration 4, loss = 0.22227210\n",
      "Iteration 5, loss = 0.20856187\n",
      "Iteration 6, loss = 0.19602776\n",
      "Iteration 7, loss = 0.18381021\n",
      "Iteration 8, loss = 0.17308509\n",
      "Iteration 9, loss = 0.16078702\n",
      "Iteration 10, loss = 0.14945692\n",
      "Iteration 11, loss = 0.13835161\n",
      "Iteration 12, loss = 0.12781925\n",
      "Iteration 13, loss = 0.11777772\n",
      "Iteration 14, loss = 0.10812274\n",
      "Iteration 15, loss = 0.09969239\n",
      "Iteration 16, loss = 0.09251037\n",
      "Iteration 17, loss = 0.08489011\n",
      "Iteration 18, loss = 0.07761640\n",
      "Iteration 19, loss = 0.07100609\n",
      "Iteration 20, loss = 0.06490295\n",
      "Iteration 21, loss = 0.05896836\n",
      "Iteration 22, loss = 0.05535024\n",
      "Iteration 23, loss = 0.05043459\n",
      "Iteration 24, loss = 0.04545437\n",
      "Iteration 25, loss = 0.04268737\n",
      "Iteration 26, loss = 0.03894732\n",
      "Iteration 27, loss = 0.03592908\n",
      "Iteration 28, loss = 0.03292122\n",
      "Iteration 29, loss = 0.03011971\n",
      "Iteration 30, loss = 0.02768620\n",
      "Iteration 31, loss = 0.02580018\n",
      "Iteration 32, loss = 0.02418513\n",
      "Iteration 33, loss = 0.02270452\n",
      "Iteration 34, loss = 0.02027464\n",
      "Iteration 35, loss = 0.01816296\n",
      "Iteration 36, loss = 0.01740122\n",
      "Iteration 37, loss = 0.01570689\n",
      "Iteration 38, loss = 0.01441850\n",
      "Iteration 39, loss = 0.01398145\n",
      "Iteration 40, loss = 0.01255884\n",
      "Iteration 41, loss = 0.01233086\n",
      "Iteration 42, loss = 0.01127126\n",
      "Iteration 43, loss = 0.01022797\n",
      "Iteration 44, loss = 0.00942078\n",
      "Iteration 45, loss = 0.00916511\n",
      "Iteration 46, loss = 0.00863036\n",
      "Iteration 47, loss = 0.00812858\n",
      "Iteration 48, loss = 0.00777054\n",
      "Iteration 49, loss = 0.00702825\n",
      "Iteration 50, loss = 0.00678849\n",
      "Iteration 51, loss = 0.00636928\n",
      "Iteration 52, loss = 0.00551361\n",
      "Iteration 53, loss = 0.00585036\n",
      "Iteration 54, loss = 0.00560322\n",
      "Iteration 55, loss = 0.00448635\n",
      "Iteration 56, loss = 0.00418718\n",
      "Iteration 57, loss = 0.00375088\n",
      "Iteration 58, loss = 0.00364382\n",
      "Iteration 59, loss = 0.00351826\n",
      "Iteration 60, loss = 0.00506113\n",
      "Iteration 61, loss = 0.00782334\n",
      "Iteration 62, loss = 0.00531039\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training accuracy: 0.999300398235\n",
      "Validation accuracy: 0.869249394673\n",
      "40-layer network:\n",
      "Iteration 1, loss = 0.37300765\n",
      "Iteration 2, loss = 0.27246942\n",
      "Iteration 3, loss = 0.24563325\n",
      "Iteration 4, loss = 0.22954728\n",
      "Iteration 5, loss = 0.21680556\n",
      "Iteration 6, loss = 0.20578959\n",
      "Iteration 7, loss = 0.19456397\n",
      "Iteration 8, loss = 0.18388107\n",
      "Iteration 9, loss = 0.17363297\n",
      "Iteration 10, loss = 0.16340145\n",
      "Iteration 11, loss = 0.15402452\n",
      "Iteration 12, loss = 0.14313727\n",
      "Iteration 13, loss = 0.13470045\n",
      "Iteration 14, loss = 0.12615757\n",
      "Iteration 15, loss = 0.11763838\n",
      "Iteration 16, loss = 0.10968935\n",
      "Iteration 17, loss = 0.10292945\n",
      "Iteration 18, loss = 0.09635163\n",
      "Iteration 19, loss = 0.08980160\n",
      "Iteration 20, loss = 0.08479417\n",
      "Iteration 21, loss = 0.07996953\n",
      "Iteration 22, loss = 0.07552745\n",
      "Iteration 23, loss = 0.06966983\n",
      "Iteration 24, loss = 0.06569873\n",
      "Iteration 25, loss = 0.06155435\n",
      "Iteration 26, loss = 0.05867986\n",
      "Iteration 27, loss = 0.05395792\n",
      "Iteration 28, loss = 0.05102204\n",
      "Iteration 29, loss = 0.04858911\n",
      "Iteration 30, loss = 0.04495201\n",
      "Iteration 31, loss = 0.04160098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.03954203\n",
      "Iteration 33, loss = 0.03723090\n",
      "Iteration 34, loss = 0.03477735\n",
      "Iteration 35, loss = 0.03346666\n",
      "Iteration 36, loss = 0.03113745\n",
      "Iteration 37, loss = 0.02865982\n",
      "Iteration 38, loss = 0.02850487\n",
      "Iteration 39, loss = 0.02680206\n",
      "Iteration 40, loss = 0.02425797\n",
      "Iteration 41, loss = 0.02343974\n",
      "Iteration 42, loss = 0.02185842\n",
      "Iteration 43, loss = 0.02047407\n",
      "Iteration 44, loss = 0.01923999\n",
      "Iteration 45, loss = 0.01792953\n",
      "Iteration 46, loss = 0.01683841\n",
      "Iteration 47, loss = 0.01580859\n",
      "Iteration 48, loss = 0.01527082\n",
      "Iteration 49, loss = 0.01545139\n",
      "Iteration 50, loss = 0.01455569\n",
      "Iteration 51, loss = 0.01405930\n",
      "Iteration 52, loss = 0.01362224\n",
      "Iteration 53, loss = 0.01273870\n",
      "Iteration 54, loss = 0.01111698\n",
      "Iteration 55, loss = 0.01082054\n",
      "Iteration 56, loss = 0.01019823\n",
      "Iteration 57, loss = 0.00958377\n",
      "Iteration 58, loss = 0.00921532\n",
      "Iteration 59, loss = 0.00912485\n",
      "Iteration 60, loss = 0.00749226\n",
      "Iteration 61, loss = 0.00774205\n",
      "Iteration 62, loss = 0.00864034\n",
      "Iteration 63, loss = 0.00880273\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training accuracy: 0.999300398235\n",
      "Validation accuracy: 0.868603712672\n",
      "20-layer network:\n",
      "Iteration 1, loss = 0.64320371\n",
      "Iteration 2, loss = 0.34108770\n",
      "Iteration 3, loss = 0.28774630\n",
      "Iteration 4, loss = 0.26241395\n",
      "Iteration 5, loss = 0.24657346\n",
      "Iteration 6, loss = 0.23527123\n",
      "Iteration 7, loss = 0.22645472\n",
      "Iteration 8, loss = 0.21957629\n",
      "Iteration 9, loss = 0.21218352\n",
      "Iteration 10, loss = 0.20606733\n",
      "Iteration 11, loss = 0.20018186\n",
      "Iteration 12, loss = 0.19492084\n",
      "Iteration 13, loss = 0.18938390\n",
      "Iteration 14, loss = 0.18369823\n",
      "Iteration 15, loss = 0.17830653\n",
      "Iteration 16, loss = 0.17319174\n",
      "Iteration 17, loss = 0.16725870\n",
      "Iteration 18, loss = 0.16180630\n",
      "Iteration 19, loss = 0.15671657\n",
      "Iteration 20, loss = 0.15148639\n",
      "Iteration 21, loss = 0.14628275\n",
      "Iteration 22, loss = 0.14113493\n",
      "Iteration 23, loss = 0.13639848\n",
      "Iteration 24, loss = 0.13194370\n",
      "Iteration 25, loss = 0.12748017\n",
      "Iteration 26, loss = 0.12358187\n",
      "Iteration 27, loss = 0.11910651\n",
      "Iteration 28, loss = 0.11500280\n",
      "Iteration 29, loss = 0.11141384\n",
      "Iteration 30, loss = 0.10840607\n",
      "Iteration 31, loss = 0.10446308\n",
      "Iteration 32, loss = 0.10087887\n",
      "Iteration 33, loss = 0.09894026\n",
      "Iteration 34, loss = 0.09556137\n",
      "Iteration 35, loss = 0.09222130\n",
      "Iteration 36, loss = 0.09014082\n",
      "Iteration 37, loss = 0.08711776\n",
      "Iteration 38, loss = 0.08479450\n",
      "Iteration 39, loss = 0.08321205\n",
      "Iteration 40, loss = 0.08060713\n",
      "Iteration 41, loss = 0.07818806\n",
      "Iteration 42, loss = 0.07632554\n",
      "Iteration 43, loss = 0.07394527\n",
      "Iteration 44, loss = 0.07227962\n",
      "Iteration 45, loss = 0.06958984\n",
      "Iteration 46, loss = 0.06795583\n",
      "Iteration 47, loss = 0.06641894\n",
      "Iteration 48, loss = 0.06461467\n",
      "Iteration 49, loss = 0.06263710\n",
      "Iteration 50, loss = 0.06115677\n",
      "Iteration 51, loss = 0.05993898\n",
      "Iteration 52, loss = 0.05779243\n",
      "Iteration 53, loss = 0.05719219\n",
      "Iteration 54, loss = 0.05564321\n",
      "Iteration 55, loss = 0.05406463\n",
      "Iteration 56, loss = 0.05258585\n",
      "Iteration 57, loss = 0.05123478\n",
      "Iteration 58, loss = 0.04942289\n",
      "Iteration 59, loss = 0.04823989\n",
      "Iteration 60, loss = 0.04717532\n",
      "Iteration 61, loss = 0.04636015\n",
      "Iteration 62, loss = 0.04557547\n",
      "Iteration 63, loss = 0.04399546\n",
      "Iteration 64, loss = 0.04287266\n",
      "Iteration 65, loss = 0.04133399\n",
      "Iteration 66, loss = 0.04102500\n",
      "Iteration 67, loss = 0.03920440\n",
      "Iteration 68, loss = 0.03800101\n",
      "Iteration 69, loss = 0.03750000\n",
      "Iteration 70, loss = 0.03670273\n",
      "Iteration 71, loss = 0.03575938\n",
      "Iteration 72, loss = 0.03506732\n",
      "Iteration 73, loss = 0.03499723\n",
      "Iteration 74, loss = 0.03335688\n",
      "Iteration 75, loss = 0.03215063\n",
      "Iteration 76, loss = 0.03175733\n",
      "Iteration 77, loss = 0.03060074\n",
      "Iteration 78, loss = 0.02962406\n",
      "Iteration 79, loss = 0.02916736\n",
      "Iteration 80, loss = 0.02817433\n",
      "Iteration 81, loss = 0.02788884\n",
      "Iteration 82, loss = 0.02748836\n",
      "Iteration 83, loss = 0.02537750\n",
      "Iteration 84, loss = 0.02553918\n",
      "Iteration 85, loss = 0.02448062\n",
      "Iteration 86, loss = 0.02358371\n",
      "Iteration 87, loss = 0.02360092\n",
      "Iteration 88, loss = 0.02358310\n",
      "Iteration 89, loss = 0.02290612\n",
      "Iteration 90, loss = 0.02189589\n",
      "Iteration 91, loss = 0.02163885\n",
      "Iteration 92, loss = 0.02096723\n",
      "Iteration 93, loss = 0.02025002\n",
      "Iteration 94, loss = 0.01990376\n",
      "Iteration 95, loss = 0.01926614\n",
      "Iteration 96, loss = 0.01825427\n",
      "Iteration 97, loss = 0.01851269\n",
      "Iteration 98, loss = 0.01789774\n",
      "Iteration 99, loss = 0.01740614\n",
      "Iteration 100, loss = 0.01711129\n",
      "Iteration 101, loss = 0.01701147\n",
      "Iteration 102, loss = 0.01679984\n",
      "Iteration 103, loss = 0.01625445\n",
      "Iteration 104, loss = 0.01530655\n",
      "Iteration 105, loss = 0.01566810\n",
      "Iteration 106, loss = 0.01579362\n",
      "Iteration 107, loss = 0.01529500\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training accuracy: 0.998277903347\n",
      "Validation accuracy: 0.848264729621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train_Tx = scaler.transform(X_train)  \n",
    "X_test_Tx = scaler.transform(X_test) \n",
    "\n",
    "# Fit models that require scaling (e.g. neural networks)\n",
    "hl_sizes = [150,100,80,60,40,20]\n",
    "nn_clfs = [MLPClassifier(hidden_layer_sizes=(size,), random_state=2345, verbose=True) for size in hl_sizes]\n",
    "\n",
    "for num, nn_clf in enumerate(nn_clfs):\n",
    "    print(str(hl_sizes[num]) + '-layer network:')\n",
    "    nn_clf.fit(X_train_Tx, y_train.ravel())\n",
    "    print('Training accuracy: ' + str(nn_clf.score(X_train_Tx, y_train)))\n",
    "    print('Validation accuracy: ' + str(nn_clf.score(X_test_Tx, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
